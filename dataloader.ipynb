{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dataloader for road kill image\n",
    "14 Nov 2022\n",
    "Livie\n",
    "Yumeng Li\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.image_dir = './data/public-images'\n",
    "        self.target_dir = './data/public-target'\n",
    "        # # load folder file list\n",
    "        self.image_ls = os.listdir(self.image_dir)\n",
    "        self.target_ls = os.listdir(self.target_dir)\n",
    "        # define how to map str label to number \n",
    "        # self.class_map = {\"Andrena fulva\" : 0, \"Panurgus banksianus\": 1, \"Lasioglossum punctatissimum\": 2}\n",
    "        # set size for images(not all images have the same size)\n",
    "        self.img_dim = (4200, 2800)\n",
    "    def __len__(self):\n",
    "        return len(self.target_ls)\n",
    "    def __getitem__(self, idx):\n",
    "        # get label and filename from the loaded dataframe\n",
    "        tgt_name = self.target_ls[idx]\n",
    "        img_name = tgt_name[:-4]+'.jpge'\n",
    "        tgt_path = os.path.join(self.target_dir,tgt_name)\n",
    "        img_path = os.path.join(self.image_dir,img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, self.img_dim, interpolation = cv2.INTER_AREA)\n",
    "        tgt = np.loadtxt(tgt_path)\n",
    "        tgt = cv2.resize(tgt, self.img_dim, interpolation = cv2.INTER_AREA)[:,:,np.newaxis]\n",
    "        # tgt = np.pad(tgt,)\n",
    "        img_tensor = torch.from_numpy(img)\n",
    "        img_tensor = img_tensor.permute(2, 0, 1)\n",
    "        # create sensor for label\n",
    "        tgt_tensor = torch.from_numpy(tgt)\n",
    "        tgt_tensor = tgt_tensor.permute(2, 0, 1)\n",
    "        return img_tensor, tgt_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CustomDataset object at 0x7f8f58e20550>\n",
      "Batch of images has shape:  torch.Size([10, 3, 2800, 4200])\n",
      "Batch of labels has shape:  torch.Size([10, 1, 2800, 4200])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = CustomDataset( )\n",
    "    print(dataset)\n",
    "    data_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "    for imgs, labels in data_loader:\n",
    "        print(\"Batch of images has shape: \",imgs.shape)\n",
    "        print(\"Batch of labels has shape: \", labels.shape)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('roadkill')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea41beba1f519d1d4dcb6adfad9d34bac36624c7e369a0994f8dda19ed6843f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
