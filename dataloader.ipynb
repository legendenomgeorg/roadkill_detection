{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dataloader for road kill image\n",
    "14 Nov 2022\n",
    "Livie\n",
    "Yumeng Li\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, target_type = 'poly'):\n",
    "        self.image_dir = './data/public-images'\n",
    "        self.annotation_dir = './data/public-annotation'\n",
    "        # # load folder file list\n",
    "        self.image_ls = os.listdir(self.image_dir)\n",
    "        self.annotation_ls = os.listdir(self.annotation_dir)\n",
    "        # set size for images(not all images have the same size)\n",
    "        self.img_dim = (1280, 960)\n",
    "        self.target_type = target_type\n",
    "    def __len__(self):\n",
    "        return len(self.annotation_ls)\n",
    "\n",
    "    def convert_box(self, file, type=\"bb\"):\n",
    "        ## eg. file = vlcsnap-2021-06-06-20h10m22s280.json\n",
    "        path_json = os.path.join(self.annotation_dir, file)\n",
    "        image_file = file.replace(\".json\",\".jpeg\")\n",
    "        img = cv2.imread(os.path.join(self.image_dir, image_file))\n",
    "        try:\n",
    "                with open(path_json) as json_file:\n",
    "                        data = json.load(json_file)\n",
    "                if data[\"annotations\"] == []:\n",
    "                        bm = np.zeros(img.shape[0:2])\n",
    "                        print('null:',path_json)\n",
    "                else:       \n",
    "                        box = data[\"annotations\"][0][\"bounding_box\"]\n",
    "                        x,y,w,h = int(box[\"x\"]),int(box[\"y\"]),int(box[\"w\"]),int(box[\"h\"])\n",
    "                        bm = np.zeros(img.shape[0:2])\n",
    "                        bm[y:y+h,x:x+w] = 1\n",
    "        except:\n",
    "                print(path_json)\n",
    "        return img, bm\n",
    "\n",
    "    def convert_polygon(self, file, type=\"bb\"):\n",
    "        ## eg. file = vlcsnap-2021-06-06-20h10m22s280.json\n",
    "        path_json = os.path.join(self.annotation_dir, file)\n",
    "        image_file = file.replace(\".json\",\".jpeg\")\n",
    "        img = cv2.imread(os.path.join(self.image_dir, image_file))\n",
    "        try:\n",
    "                with open(path_json) as json_file:\n",
    "                        data = json.load(json_file)\n",
    "                if data[\"annotations\"] == []:\n",
    "                        mask = np.zeros(img.shape[:2], dtype=\"float64\")\n",
    "                        # bm = np.int8(bm)\n",
    "                        print('null:',path_json)\n",
    "                else:       \n",
    "                        mask = np.zeros(img.shape[:2], dtype=\"float64\")\n",
    "                        pts = data[\"annotations\"][0][\"polygon\"][\"path\"]\n",
    "                        pts = np.array([[pt[\"x\"],pt[\"y\"]] for pt in pts],dtype=np.int32)\n",
    "                        cv2.fillPoly(mask, pts =[pts], color=(255,0,0))\n",
    "                        # target = cv2.bitwise_and(img, img, mask=mask)\n",
    "                        # plt.imshow(target)\n",
    "                        \n",
    "                # np.savetxt(os.path.join(target_folder, txt_file), bm, fmt = '%s')\n",
    "        except:\n",
    "                print(path_json)\n",
    "        return img, mask\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        tgt_name = self.annotation_ls[idx]\n",
    "        if self.target_type == 'box':\n",
    "                img,tgt = self.convert_box(tgt_name)\n",
    "        elif self.target_type == 'poly':\n",
    "                img,tgt = self.convert_polygon(tgt_name)\n",
    "        else:\n",
    "                raise Exception('wrong type')\n",
    "        # get label and filename from the loaded dataframe\n",
    "        img = cv2.resize(img, self.img_dim, interpolation = cv2.INTER_AREA)\n",
    "        tgt = cv2.resize(tgt, self.img_dim, interpolation = cv2.INTER_AREA)[:,:,np.newaxis]\n",
    "        img_tensor = torch.Tensor(img)[:,:,[2,1,0]]\n",
    "        img_tensor = img_tensor.permute(2, 0, 1)\n",
    "        # create sensor for label\n",
    "        tgt_tensor = torch.Tensor(tgt)\n",
    "        tgt_tensor = tgt_tensor.permute(2, 0, 1)\n",
    "        return img_tensor, tgt_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CustomDataset object at 0x7f8d1bbb5ea0>\n",
      "Batch of images has shape:  torch.FloatTensor\n",
      "Batch of labels has shape:  torch.Size([10, 1, 960, 1280])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = CustomDataset(target_type = 'box')\n",
    "    print(dataset)\n",
    "    data_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "    for img, label in data_loader:\n",
    "        # plt1 = plt.figure()\n",
    "        # plt1 = plt.imshow(img[0,:,:,:])\n",
    "        # plt2 = plt.figure()\n",
    "        # plt2 = plt.imshow(label[0,0,:,:])\n",
    "        print(\"Batch of images has shape: \",img.type())\n",
    "        print(\"Batch of labels has shape: \", label.shape)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('roadkill')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea41beba1f519d1d4dcb6adfad9d34bac36624c7e369a0994f8dda19ed6843f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
