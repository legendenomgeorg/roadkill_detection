{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from CustomDataset import CustomDataset\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda-2022.05/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda-2022.05/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=FCN_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=FCN_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "#Initializations\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torchvision.models.segmentation.fcn_resnet50(pretrained=True).to(device)\n",
    "\n",
    "#has to normalize data the same way the pretrained images were\n",
    "normalize = transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                        std=[0.229,0.224,0.225])\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}\n",
    "dataset = CustomDataset(target_type = 'poly')\n",
    "\n",
    "TRAIN_SIZE= math.floor(dataset.__len__()*0.75)\n",
    "TEST_SIZE = dataset.__len__() - TRAIN_SIZE\n",
    "trainset, testset = random_split(dataset,[TRAIN_SIZE,TEST_SIZE])\n",
    "\n",
    "\n",
    "traindata_loader = DataLoader(trainset, batch_size=5, shuffle=True)\n",
    "testdata_loader = DataLoader(testset, batch_size=5, shuffle=True)\n",
    "# data_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "image_datasets = {\n",
    "    'train': \n",
    "        TRAIN_SIZE,\n",
    "    'validation':\n",
    "        TEST_SIZE\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train':\n",
    "        traindata_loader,\n",
    "    'validation':\n",
    "        testdata_loader\n",
    "}\n",
    "\n",
    "for name,param in model.named_parameters():\n",
    "    if 'FCNHead' not in name:\n",
    "        param.requires_grad = False  \n",
    "print(model.classifier[4])\n",
    "\n",
    "model.classifier[4] = nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1)).to(device)\n",
    "\n",
    "#model.fc = nn.Sequential(\n",
    "#               nn.Linear(2048, 128),\n",
    "#               nn.ReLU(inplace=True),\n",
    "#               nn.Linear(128, 2)).to(device)\n",
    "params_to_update = []\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        \n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.NLLLoss()\n",
    "optim = optim.Adam((model.classifier[4].parameters()))\n",
    "print(model.classifier[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 960, 1280])\n",
      "torch.Size([5, 960, 1280])\n"
     ]
    }
   ],
   "source": [
    "for batch, (inputs,labels) in enumerate(dataloaders['train']):\n",
    "# for inputs,labels in enumerate(dataloaders[phase]):\n",
    "    # inputs = inputs.to(device)\n",
    "    # labels = labels.to(device)\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=3, evaluate = False):\n",
    "    epoch_loss_list = []\n",
    "    epoch_acc_list = []\n",
    "    phases = ['train', 'validation']\n",
    "    if evaluate == True:\n",
    "        phases = ['validation']\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in phases:\n",
    "            print(\"Currently in the: \", phase,\" phase\")\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            total = 0\n",
    "            running_corrects = 0\n",
    "            acc = 0\n",
    "            for batch, (inputs,labels) in enumerate(dataloaders[phase]):\n",
    "            # for inputs,labels in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # print(inputs.dtype,labels.dtype)\n",
    "                # DON'T USE ARGMAX HERE\n",
    "                # labels = torch.argmax(labels, dim=1)\n",
    "                outputs = model(inputs)[\"out\"]\n",
    "                # print(labels.max, labels.min)\n",
    "                \n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                total += labels.nelement()\n",
    "                running_corrects += preds.eq(labels.data).sum().item()\n",
    "                ## TODO\n",
    "                # mean IoU\n",
    "                # FP, FN\n",
    "                acc = running_corrects/total\n",
    "            # Plotting a random image at the end of all epochs\n",
    "            plt1 = plt.figure()\n",
    "            plt1 = plt.imshow(preds.cpu()[0])\n",
    "            plt2 = plt.figure()\n",
    "            plt2 = plt.imshow(labels.data.cpu()[0])\n",
    "            # Calculating loss and acc\n",
    "            epoch_loss = running_loss / image_datasets[phase]\n",
    "            epoch_loss_list.append(epoch_loss)\n",
    "            epoch_acc = acc / image_datasets[phase]\n",
    "            epoch_acc_list.append(epoch_acc)\n",
    "            \n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss,\n",
    "                                                        epoch_acc))\n",
    "    return model, epoch_loss_list, epoch_acc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently in the:  train  phase\n",
      "null: ./data/public-annotation/grayfoxMay2011.json\n",
      "null: ./data/public-annotation/P1010547%20%281%29.json\n",
      "null: ./data/public-annotation/395%20Owl.json\n",
      "null: ./data/public-annotation/A_Bighorn_BadwaterRoad_MM_35_20121001.json\n",
      "null: ./data/public-annotation/P1010851.json\n",
      "train loss: -9.0440, acc: 0.0011\n",
      "Currently in the:  validation  phase\n",
      "null: ./data/public-annotation/P1000576.json\n",
      "null: ./data/public-annotation/20180619_112554.json\n"
     ]
    }
   ],
   "source": [
    "model_trained, epoch_loss_list, epoch_acc_list = train_model(model, loss_fn, optim, num_epochs=50)\n",
    "#!mkdir models\n",
    "#!mkdir models/pytorch\n",
    "#torch.save(model_trained.state_dict(), 'models/pytorch/weights6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.segmentation.fcn_resnet50(pretrained=True)\n",
    "model.classifier[4] = nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "model.load_state_dict(torch.load('models/pytorch/weights5.h5'))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained, epoch_loss_list, epoch_acc_list = train_model(model, loss_fn, optim, num_epochs=1, evaluate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea41beba1f519d1d4dcb6adfad9d34bac36624c7e369a0994f8dda19ed6843f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
