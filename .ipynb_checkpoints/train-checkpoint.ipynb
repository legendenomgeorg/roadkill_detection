{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from CustomDataset import CustomDataset\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 174, 'validation': 58}\n",
      "a\n",
      "FCNHead(\n",
      "  (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Initializations\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = torchvision.models.segmentation.fcn_resnet50(pretrained=True, progress = True).to(device)\n",
    "\n",
    "#has to normalize data the same way the pretrained images were\n",
    "normalize = transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                        std=[0.229,0.224,0.225])\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}\n",
    "dataset = CustomDataset(target_type = 'poly')\n",
    "\n",
    "TRAIN_SIZE= math.floor(dataset.__len__()*0.75)\n",
    "TEST_SIZE = dataset.__len__() - TRAIN_SIZE\n",
    "trainset, testset = random_split(dataset,[TRAIN_SIZE,TEST_SIZE])\n",
    "\n",
    "\n",
    "traindata_loader = DataLoader(trainset, batch_size=5, shuffle=True)\n",
    "testdata_loader = DataLoader(testset, batch_size=5, shuffle=True)\n",
    "LOADER_TRAIN_SIZE = traindata_loader.__len__()\n",
    "LOADER_TEST_SIZE = testdata_loader.__len__()\n",
    "\n",
    "image_datasets = {\n",
    "    'train': \n",
    "        LOADER_TRAIN_SIZE,\n",
    "    'validation':\n",
    "        LOADER_TEST_SIZE\n",
    "}\n",
    "print(image_datasets)\n",
    "dataloaders = {\n",
    "    'train':\n",
    "        traindata_loader,\n",
    "    'validation':\n",
    "        testdata_loader\n",
    "}\n",
    "# print(model)\n",
    "\n",
    "for name,param in model.named_parameters():\n",
    "    if 'classifier' not in name:\n",
    "        param.requires_grad = False  \n",
    "#print(model.classifier[4])\n",
    "\n",
    "model.classifier[4] = nn.Sequential(\n",
    "    nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1)).to(device),\n",
    "    nn.Sigmoid().to(device)\n",
    ")\n",
    "\n",
    "#model.fc = nn.Sequential(\n",
    "#               nn.Linear(2048, 128),\n",
    "#               nn.ReLU(inplace=True),\n",
    "#               nn.Linear(128, 2)).to(device)\n",
    "params_to_update = []\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        \n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def init(self):\n",
    "        super(diceLoss, self).init()\n",
    "    def forward(self,pred, target):\n",
    "        smooth = 1.\n",
    "        iflat = pred.contiguous().view(-1)\n",
    "        tflat = target.contiguous().view(-1)\n",
    "        intersection = (iflat * tflat).sum()\n",
    "        A_sum = torch.sum(iflat * iflat)\n",
    "        B_sum = torch.sum(tflat * tflat)\n",
    "        return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth) )\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "        \n",
    "        return Dice_BCE\n",
    "    \n",
    "    \n",
    "class FocalLoss(nn.CrossEntropyLoss):\n",
    "    ''' Focal loss for classification tasks on imbalanced datasets '''\n",
    "\n",
    "    def __init__(self, gamma, alpha=None, ignore_index=-100, reduction='none'):\n",
    "        super().__init__(weight=alpha, ignore_index=ignore_index, reduction='none')\n",
    "        self.reduction = reduction\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, input_, target):\n",
    "        cross_entropy = super().forward(input_, target)\n",
    "        # Temporarily mask out ignore index to '0' for valid gather-indices input.\n",
    "        # This won't contribute final loss as the cross_entropy contribution\n",
    "        # for these would be zero.\n",
    "        target = target * (target != self.ignore_index).long()\n",
    "        input_prob = torch.gather(F.softmax(input_, 1), 1, target.unsqueeze(1))\n",
    "        loss = torch.pow(1 - input_prob, self.gamma) * cross_entropy\n",
    "        return torch.mean(loss) if self.reduction == 'mean'else torch.sum(loss) if self.reduction == 'sum' else loss\n",
    "            \n",
    "            \n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "# loss_fn = FocalLoss(gamma=0.7)\n",
    "# loss_fn = torchvision.ops.sigmoid_focal_loss()\n",
    "# loss_fn = DiceBCELoss()\n",
    "# loss_fn = nn.NLLLoss()\n",
    "optim = optim.Adam(params_to_update, lr=0.001, eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "# optim = optim.Adam((model.classifier[4].parameters()))\n",
    "print('a')\n",
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(prediction, truth):\n",
    "    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n",
    "    tensors, i.e. the amount of positions where the values of `prediction`\n",
    "    and `truth` are\n",
    "    - 1 and 1 (True Positive)\n",
    "    - 1 and 0 (False Positive)\n",
    "    - 0 and 0 (True Negative)\n",
    "    - 0 and 1 (False Negative)\n",
    "    \"\"\"\n",
    "    threshold = torch.tensor([0.5]).to(device)\n",
    "    prediction = (prediction>threshold).float()*1\n",
    "    \n",
    "    confusion_vector = prediction / truth\n",
    "    # Element-wise division of the 2 tensors returns a new tensor which holds a\n",
    "    # unique value for each case:\n",
    "    #   1     where prediction and truth are 1 (True Positive)\n",
    "    #   inf   where prediction is 1 and truth is 0 (False Positive)\n",
    "    #   nan   where prediction and truth are 0 (True Negative)\n",
    "    #   0     where prediction is 0 and truth is 1 (False Negative)\n",
    "    # .item()\n",
    "    true_positives = torch.sum(confusion_vector == 1)\n",
    "    false_positives = torch.sum(confusion_vector == float('inf'))\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_vector))\n",
    "    false_negatives = torch.sum(confusion_vector == 0)\n",
    "\n",
    "    return true_positives, false_positives, true_negatives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 480, 640])\n",
      "torch.Size([5, 480, 640])\n"
     ]
    }
   ],
   "source": [
    "for batch, (inputs,labels) in enumerate(dataloaders['train']):\n",
    "# for inputs,labels in enumerate(dataloaders[phase]):\n",
    "    # inputs = inputs.to(device)\n",
    "    # labels = labels.to(device)\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "def train_model(model, optimizer, save_dir, num_epochs=3, evaluate = True):\n",
    "    # epoch_loss_list = []\n",
    "    # epoch_f1_list = []\n",
    "    # epoch_roc_list = []\n",
    "    phases = ['train']\n",
    "    if evaluate == True:\n",
    "        phases = ['train','validation']\n",
    "    train_performance = []\n",
    "    test_performance = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in phases:\n",
    "            print(\"Currently in the: \", phase,\" phase\")\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            total = 0\n",
    "            # running_corrects = 0\n",
    "            running_tp = 0\n",
    "            running_fp = 0\n",
    "            running_tn = 0\n",
    "            running_fn = 0\n",
    "            conf_tp = 0\n",
    "            conf_fp = 0\n",
    "            conf_tn = 0\n",
    "            conf_fn = 0\n",
    "            conf_precision = 0\n",
    "            conf_recall = 0\n",
    "            metrics_f1 = 0\n",
    "            metrics_roc = 0\n",
    "            missing_roc = 0\n",
    "            for batch, (inputs,labels) in enumerate(dataloaders[phase]):\n",
    "            # for inputs,labels in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # print(inputs.dtype,labels.dtype)\n",
    "                # DON'T USE ARGMAX HERE\n",
    "                #labels = torch.argmax(labels, dim=0)\n",
    "                outputs = model(inputs)[\"out\"]\n",
    "                # print(outputs.shape, outputs.max(), outputs.min())\n",
    "                \n",
    "                preds = torch.squeeze(outputs).float().requires_grad_()\n",
    "                \n",
    "                loss = torchvision.ops.sigmoid_focal_loss(preds, torch.squeeze(labels), reduction = 'mean')\n",
    "                \n",
    "                # loss = criterion(outputs, labels.long())\n",
    "                # print(loss)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                # _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                total += labels.nelement()\n",
    "                # running_corrects += preds.eq(labels.data).sum().item()\n",
    "                # acc += running_corrects/total\n",
    "                \n",
    "                \n",
    "                #print(running_loss)\n",
    "                if (epoch == (num_epochs-1)) and (phase != 'train'):\n",
    "                    plt1 = plt.figure()\n",
    "                    plt1 = plt.imshow(preds.cpu().detach().numpy()[0])\n",
    "\n",
    "                    plt2 = plt.figure()\n",
    "                    plt2 = plt.imshow(labels.data.cpu()[0])\n",
    "                    \n",
    "                tp, fp, tn, fn = confusion(preds, labels.data)\n",
    "                # print(tp, fp, tn, fn)\n",
    "                \n",
    "                running_tp += tp\n",
    "                running_fp += fp\n",
    "                running_tn += tn\n",
    "                running_fn += fn\n",
    "                conf_tp += running_tp/total\n",
    "                conf_fp += running_fp/total\n",
    "                conf_tn += running_tn/total\n",
    "                conf_fn += running_fn/total\n",
    "                conf_precision += running_tp/(running_tp+running_fp)\n",
    "                conf_recall += running_tp/(running_tp+running_fn)\n",
    "                \n",
    "                # print(total)\n",
    "                # print(conf_tp, conf_fp, conf_tn, conf_fn, acc)\n",
    "                \n",
    "                metrics_f1 += f1_score(labels.cpu().ravel()>0, preds.cpu().ravel()>0.5)\n",
    "                try:\n",
    "                    metrics_roc += roc_auc_score(labels.cpu().int().ravel().detach().numpy(),preds.cpu().ravel().detach().numpy())\n",
    "                except:\n",
    "                    missing_roc += 1\n",
    "                    continue\n",
    "                # print(metrics_f1, metrics_roc)\n",
    "            # Calculating loss and acc\n",
    "            \n",
    "            epoch_loss = running_loss / image_datasets[phase]\n",
    "            # epoch_loss_list.append(epoch_loss)\n",
    "            epoch_precision = conf_precision / image_datasets[phase]\n",
    "            epoch_recall = conf_recall / image_datasets[phase]\n",
    "            epoch_f1 = epoch_precision*epoch_recall/(epoch_precision+epoch_recall)\n",
    "            epoch_metrics_f1 = metrics_f1 / image_datasets[phase]\n",
    "            epoch_metrics_roc = metrics_roc / (image_datasets[phase] - missing_roc)\n",
    "            # epoch_f1_list.append(epoch_metrics_f1)\n",
    "            # epoch_roc_list.append(epoch_metrics_roc)\n",
    "            # epoch_confmat = (conf_tp, conf_fp, conf_tn, conf_fn)/image_datasets[phase]\n",
    "            # epoch_confmat_list.append(epoch_confmat)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                performance = [epoch, epoch_loss, epoch_metrics_f1, epoch_metrics_roc]\n",
    "            else:\n",
    "                performance.extend((epoch_loss, epoch_metrics_f1, epoch_metrics_roc))\n",
    "                print(performance)\n",
    "                with open(os.path.join(save_dir, 'fcn_log.csv'), 'a+', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(performance)\n",
    "\n",
    "            \n",
    "            print('epoch: {} {} loss: {:.4f}, '.format(epoch,phase,\n",
    "                                                        epoch_loss))\n",
    "            print('f1 score: {:.4f}, precision: {:.4f}, recall: {:.4f}'.format(epoch_f1,\n",
    "                                                                              epoch_precision,\n",
    "                                                                              epoch_recall))\n",
    "            print('TP: {:.4f}, FP: {:.4f}, TN: {:.4f}, FN: {:.4f}'. format(\n",
    "                                                        conf_tp/image_datasets[phase],\n",
    "                                                        conf_fp/image_datasets[phase],\n",
    "                                                        conf_tn/image_datasets[phase],\n",
    "                                                        conf_fn/image_datasets[phase])\n",
    "                                                        )\n",
    "            best_loss = 1\n",
    "            if phase == 'validation' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model, os.path.join(save_dir, 'fcn_resnet50_200epoch.pt'))\n",
    "    gpu_usage()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 61% |\n",
      "|  1 |  0% | 44% |\n",
      "Currently in the:  train  phase\n"
     ]
    }
   ],
   "source": [
    "gpu_usage()\n",
    "save_dir = os.path.join(os.getcwd(),'models/pytorch')\n",
    "model_trained = train_model(model, optim, save_dir, num_epochs=200)\n",
    "#!mkdir models\n",
    "#!mkdir models/pytorch\n",
    "\n",
    "# torch.save(model_trained.state_dict(), 'models/pytorch/weights_dec04_fcn_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.segmentation.fcn_resnet50(pretrained=True)\n",
    "model.classifier[4] = nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "model.load_state_dict(torch.load('models/pytorch/weights6.h5'))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_trained, epoch_loss_list, epoch_f1_list = train_model(model, loss_fn, optim, num_epochs=1, evaluate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = [0.1,0.2,0.3]\n",
    "with open(os.path.join(save_dir, 'fcn_log.csv'), 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(performance)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea41beba1f519d1d4dcb6adfad9d34bac36624c7e369a0994f8dda19ed6843f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
