{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from CustomDataset import CustomDataset\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda-2022.05/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda-2022.05/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=FCN_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=FCN_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "#Initializations\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torchvision.models.segmentation.fcn_resnet50(pretrained=True).to(device)\n",
    "\n",
    "#has to normalize data the same way the pretrained images were\n",
    "normalize = transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                        std=[0.229,0.224,0.225])\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}\n",
    "dataset = CustomDataset(target_type = 'poly')\n",
    "\n",
    "TRAIN_SIZE= math.floor(dataset.__len__()*0.75)\n",
    "TEST_SIZE = dataset.__len__() - TRAIN_SIZE\n",
    "trainset, testset = random_split(dataset,[TRAIN_SIZE,TEST_SIZE])\n",
    "\n",
    "\n",
    "traindata_loader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "testdata_loader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "# data_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "image_datasets = {\n",
    "    'train': \n",
    "        TRAIN_SIZE,\n",
    "    'validation':\n",
    "        TEST_SIZE\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train':\n",
    "        traindata_loader,\n",
    "    'validation':\n",
    "        testdata_loader\n",
    "}\n",
    "\n",
    "for name,param in model.named_parameters():\n",
    "    if 'FCNHead' not in name:\n",
    "        param.requires_grad = False  \n",
    "print(model.classifier[4])\n",
    "\n",
    "model.classifier[4] = nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1)).to(device)\n",
    "\n",
    "#model.fc = nn.Sequential(\n",
    "#               nn.Linear(2048, 128),\n",
    "#               nn.ReLU(inplace=True),\n",
    "#               nn.Linear(128, 2)).to(device)\n",
    "params_to_update = []\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = optim.Adam((model.classifier[4].parameters()))\n",
    "print(model.classifier[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 960, 1280])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for batch, (inputs,labels) in enumerate(dataloaders['train']):\n",
    "# for inputs,labels in enumerate(dataloaders[phase]):\n",
    "    # inputs = inputs.to(device)\n",
    "    # labels = labels.to(device)\n",
    "    print(inputs.shape)\n",
    "    print(labels.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for batch, (inputs,labels) in enumerate(dataloaders[phase]):\n",
    "            # for inputs,labels in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # print(inputs.dtype)\n",
    "                # print(labels.dtype)\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "                outputs = model(inputs)[\"out\"]\n",
    "                #print(outputs[\"out\"].shape, labels.shape)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / image_datasets[phase]\n",
    "            epoch_acc = running_corrects.double() / image_datasets[phase]\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss,\n",
    "                                                        epoch_acc))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null: ./data/public-annotation/P1010851.json\n",
      "null: ./data/public-annotation/20180619_112554.json\n",
      "null: ./data/public-annotation/A_Bighorn_BadwaterRoad_MM_35_20121001.json\n",
      "null: ./data/public-annotation/grayfoxMay2011.json\n",
      "null: ./data/public-annotation/P1000576.json\n",
      "null: ./data/public-annotation/IMG_0836.json\n",
      "null: ./data/public-annotation/P1010547%20%281%29.json\n",
      "null: ./data/public-annotation/395%20Owl.json\n",
      "train loss: 0.0361, acc: 1632684.9988\n",
      "null: ./data/public-annotation/395%20Owl.json\n",
      "null: ./data/public-annotation/P1000576.json\n",
      "null: ./data/public-annotation/P1010547%20%281%29.json\n",
      "null: ./data/public-annotation/A_Bighorn_BadwaterRoad_MM_35_20121001.json\n",
      "null: ./data/public-annotation/20180619_112554.json\n",
      "null: ./data/public-annotation/IMG_0836.json\n",
      "null: ./data/public-annotation/grayfoxMay2011.json\n",
      "null: ./data/public-annotation/P1010851.json\n",
      "validation loss: 0.0093, acc: 4910948.0969\n"
     ]
    }
   ],
   "source": [
    "model_trained = train_model(model, loss_fn, optim, num_epochs=1)\n",
    "!mkdir models\n",
    "!mkdir models/pytorch\n",
    "torch.save(model_trained.state_dict(), 'models/pytorch/weights2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda-2022.05/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/dl08e22/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0cef29ff9ef4ef4a3d9fa7cd93289fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FCN:\n\tMissing key(s) in state_dict: \"fc.0.weight\", \"fc.0.bias\", \"fc.2.weight\", \"fc.2.bias\". \n\tUnexpected key(s) in state_dict: \"aux_classifier.0.weight\", \"aux_classifier.1.weight\", \"aux_classifier.1.bias\", \"aux_classifier.1.running_mean\", \"aux_classifier.1.running_var\", \"aux_classifier.1.num_batches_tracked\", \"aux_classifier.4.weight\", \"aux_classifier.4.bias\". \n\tsize mismatch for classifier.4.weight: copying a param with shape torch.Size([2, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([21, 512, 1, 1]).\n\tsize mismatch for classifier.4.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([21]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1703563/745306361.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                nn.Linear(128, 2)).to(device)\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/pytorch/weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda-2022.05/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1605\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FCN:\n\tMissing key(s) in state_dict: \"fc.0.weight\", \"fc.0.bias\", \"fc.2.weight\", \"fc.2.bias\". \n\tUnexpected key(s) in state_dict: \"aux_classifier.0.weight\", \"aux_classifier.1.weight\", \"aux_classifier.1.bias\", \"aux_classifier.1.running_mean\", \"aux_classifier.1.running_var\", \"aux_classifier.1.num_batches_tracked\", \"aux_classifier.4.weight\", \"aux_classifier.4.bias\". \n\tsize mismatch for classifier.4.weight: copying a param with shape torch.Size([2, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([21, 512, 1, 1]).\n\tsize mismatch for classifier.4.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([21])."
     ]
    }
   ],
   "source": [
    "model = torchvision.models.segmentation.fcn_resnet50(pretrained=False).to(device)\n",
    "model.fc = nn.Sequential(\n",
    "               nn.Linear(2048, 128),\n",
    "               nn.ReLU(inplace=True),\n",
    "               nn.Linear(128, 2)).to(device)\n",
    "model.load_state_dict(torch.load('models/pytorch/weights.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea41beba1f519d1d4dcb6adfad9d34bac36624c7e369a0994f8dda19ed6843f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
